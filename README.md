# ğŸ•‰ï¸ GitaGPT â€” HyDE-Enhanced QA Retrieval RAG

> A High-Trust AI Assistant for Learning and Exploring the Wisdom of the Bhagavad Gita

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-Backend-green)
![Streamlit](https://img.shields.io/badge/Streamlit-Frontend-red)
![ChromaDB](https://img.shields.io/badge/VectorDB-ChromaDB-purple)
![Groq](https://img.shields.io/badge/LLM-Llama--3.3--70B-orange)

---

# ğŸŒŸ Overview

GitaGPT is an advanced **HyDE-powered Retrieval-Augmented Generation (RAG)** system designed to deliver accurate, context-grounded explanations from the Bhagavad Gita.

Instead of retrieving isolated verses, GitaGPT retrieves **structured Questionâ€“Answer knowledge chunks**, making it optimized for learning and conceptual understanding.

Unlike naive RAG systems that rely on a single raw query, GitaGPT combines:

- ğŸ§  Hypothetical Document Expansion (HyDE)
- ğŸ” Enhanced Semantic Retrieval
- ğŸ“š Structured Q&A Chunk Retrieval
- ğŸ“– Strict Context-Constrained Answering
- ğŸ”’ Hallucination Minimization via grounded prompts

This ensures responses are:

- âœ… Contextually Accurate  
- âœ… Semantically Aligned with Scripture  
- âœ… Explanation-Oriented  
- âœ… Hallucination-Resistant  

---

# ğŸ—ï¸ Project Structure

```text
rag-project-dev/
â”‚
â”œâ”€â”€ ingest/
â”‚   â”œâ”€â”€ download_dataset.py    # Downloads Bhagavad Gita dataset
â”‚   â”œâ”€â”€ clean_dataset.py       # Cleans & standardizes raw text
â”‚   â”œâ”€â”€ chunk_dataset.py       # Converts text into structured Q&A chunks
â”‚   â””â”€â”€ embed_chunks.py        # Creates embeddings & stores in ChromaDB
â”‚
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py                # FastAPI Backend (HyDE + Retrieval Logic)
â”‚
â”œâ”€â”€ app.py                     # Streamlit Frontend
â”‚
â”œâ”€â”€ setup.sh                   # Creates venv & installs dependencies (macOS/Linux)
â”œâ”€â”€ activate.sh                # Activates virtual environment
â”œâ”€â”€ deactivate.sh              # Deactivates virtual environment
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env
```

---

# ğŸ”„ Data Ingestion Pipeline (Structured ETL)

GitaGPT follows a clean and modular ingestion workflow.

## 1ï¸âƒ£ Download Dataset

```bash
python ingest/download_dataset.py
```

## 2ï¸âƒ£ Clean Dataset

```bash
python ingest/clean_dataset.py
```

- Removes formatting noise  
- Normalizes text  
- Prepares data for structured processing  

## 3ï¸âƒ£ Chunk Dataset (Q&A Structured)

```bash
python ingest/chunk_dataset.py
```

This converts the dataset into structured Questionâ€“Answer chunks optimized for retrieval.

## 4ï¸âƒ£ Embed & Store

```bash
python ingest/embed_chunks.py
```

- Uses `all-MiniLM-L6-v2`
- Stores embeddings in **ChromaDB**
- Creates persistent vector store:

```
ingest/chroma_db/
```

---

# ğŸ“¦ Chunk Format

Chunks are stored as structured Q&A objects:

```json
{
  "text": "Question: ... Answer: ...",
  "metadata": {
    "source_question": "...",
    "chunk_index": 0,
    "total_chunks": 1
  }
}
```

This means retrieval is:

- Question-aware  
- Context-preserving  
- Explanation-focused  

Instead of retrieving raw verses, GitaGPT retrieves **pre-structured explanatory knowledge units**.

---

# ğŸ§  RAG Architecture

## ğŸ” Step 1 â€” HyDE Query Expansion

Before retrieval, the system generates a **hypothetical Gita-style explanation** based on the user's question.

Example:

User:
> How do I control stress?

HyDE generates:
> The restless mind, disturbed by worldly agitation, must be steadied through discipline and detachment...

This bridges the gap between:

- Modern language  
- Scriptural terminology  

Technique used:

> **HyDE (Hypothetical Document Embeddings)**

---

## ğŸ“š Step 2 â€” Enhanced Semantic Retrieval

Search Query:

```
User Question + HyDE Expansion
```

Then:

- Top 5 semantically similar Q&A chunks retrieved from ChromaDB  
- Improved alignment with spiritual vocabulary  
- Reduced irrelevant matches  

---

## ğŸ“– Step 3 â€” Context-Grounded QA Generation

System constraint:

```
Answer ONLY using the context.
Limit to 5â€“6 lines.
```

This guarantees:

- No external knowledge  
- No speculation  
- Answer derived strictly from retrieved Q&A chunks  

---

# âš™ï¸ Environment Setup

## ğŸ§ macOS / Linux (Recommended)

### 1ï¸âƒ£ Run Automated Setup

```bash
bash setup.sh
```

This will:

- Create `venv/`
- Activate environment
- Upgrade pip
- Install dependencies

### â–¶ï¸ Activate

```bash
source activate.sh
```

### â¹ï¸ Deactivate

```bash
source deactivate.sh
```

---

## ğŸªŸ Windows Setup

`setup.sh` is not supported on Windows.

### 1ï¸âƒ£ Create Virtual Environment

```powershell
python -m venv venv
```

### 2ï¸âƒ£ Activate

PowerShell:

```powershell
venv\Scripts\Activate.ps1
```

Command Prompt:

```cmd
venv\Scripts\activate.bat
```

### 3ï¸âƒ£ Install Requirements

```powershell
python -m pip install --upgrade pip
pip install -r requirements.txt
```

### â¹ï¸ Deactivate

```powershell
deactivate
```

---

# ğŸš€ Running the Application

## 1ï¸âƒ£ Activate Environment

macOS / Linux:

```bash
source activate.sh
```

Windows:

```powershell
venv\Scripts\Activate.ps1
```

---

## 2ï¸âƒ£ Add API Key

Create `.env` file:

```env
GROQ_API_KEY=your_key_here
```

---

## 3ï¸âƒ£ Run Ingestion (First Time Only)

macOS / Linux:

```bash
python ingest/download_dataset.py
python ingest/clean_dataset.py
python ingest/chunk_dataset.py
python ingest/embed_chunks.py
```

Windows:

```powershell
python ingest\download_dataset.py
python ingest\clean_dataset.py
python ingest\chunk_dataset.py
python ingest\embed_chunks.py
```

---

## 4ï¸âƒ£ Start Backend

```bash
uvicorn api.main:app --reload
```

API runs at:

```
http://127.0.0.1:8000
```

---

## 5ï¸âƒ£ Launch Frontend

```bash
streamlit run app.py
```

UI runs at:

```
http://localhost:8501
```

---

# ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| LLM | Llama-3.3-70B (Groq) |
| Embeddings | all-MiniLM-L6-v2 |
| Vector Store | ChromaDB |
| Backend | FastAPI |
| Frontend | Streamlit |
| Framework | LangChain |

---

# ğŸ†š Why This Is More Advanced Than Basic RAG

| Basic RAG | GitaGPT |
|------------|---------|
| Raw user query only | HyDE-expanded query |
| Generic document chunks | Structured Q&A chunks |
| Weak semantic match | Scriptural-style expansion |
| Loose ingestion | Clean ETL pipeline |
| Higher hallucination risk | Strict context-only answering |

---

# ğŸ”’ Hallucination Resistance Strategy

- Temperature = 0  
- Context-only answering  
- Limited output length  
- No external knowledge injection  
- Retrieval from curated Q&A chunks  

---

# ğŸ§˜ Example Flow

User asks:

> Why does Dhritarashtra ask Sanjaya to describe the battlefield?

System:

1. Generates HyDE expansion  
2. Retrieves relevant Q&A chunk  
3. Uses only retrieved explanation  
4. Produces concise grounded answer  

---

# ğŸŒº Future Improvements

- [ ] Add chapter/verse metadata support
- [ ] Implement LLM-based relevance grading
- [ ] Hybrid search (BM25 + Vector)
- [ ] Sanskrit + Transliteration toggle
- [ ] Daily Learning Mode
- [ ] Audio Recitation
- [ ] Mobile App version

---

# ğŸ‘¨â€ğŸ’» Author

**Hrithik Umbarji**

Built with discipline, devotion, and a passion for spiritual learning.

---

# ğŸ•‰ï¸ Guiding Principle

â€œna hi jÃ±Änena sadá¹›Å›aá¹ pavitram iha vidyate.â€  
*There is nothing as purifying as true knowledge.* â€” Bhagavad Gita 4.38

---

â­ If this project supports your journey of learning and reflection, consider starring the repository.

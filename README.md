# ğŸ•‰ï¸ GitaGPT â€” Advanced HyDE-Based RAG for Bhagavad Gita Q&A

> A Context-Grounded Retrieval-Augmented Generation (RAG) API for Exploring the Teachings of the Bhagavad Gita

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-Backend-green)
![ChromaDB](https://img.shields.io/badge/VectorDB-ChromaDB-purple)
![Groq](https://img.shields.io/badge/LLM-Llama--3.3--70B-orange)
![Embeddings](https://img.shields.io/badge/Embeddings-all--MiniLM--L6--v2-blue)

---

# ğŸ“˜ Overview

GitaGPT is an advanced **Retrieval-Augmented Generation (RAG)** system designed to answer Bhagavad Gitaâ€“related questions using structured Q&A knowledge and semantic retrieval.

This system combines:

- ğŸ§  **HyDE (Hypothetical Document Expansion)**
- ğŸ” **Semantic Vector Search (ChromaDB)**
- ğŸ“Š **Similarity Score Threshold Filtering**
- ğŸ”’ **Strict Context-Constrained Answering**
- âš¡ **FastAPI Backend**
- ğŸ’» **Local GPU Embeddings (Apple MPS Support)**

It is optimized for:

- Conceptual understanding
- Explanation-based learning
- Reduced hallucination
- Deterministic vector storage

---

# ğŸš€ Key Features

## âœ… 1. HyDE Retrieval Enhancement

Before querying the vector database, the system generates a **hypothetical Gita-style explanation** using an LLM.

This improves semantic recall for abstract spiritual questions like:

- What is true duty?
- How to overcome attachment?
- What is karma yoga?
- What is detachment in action?

Pipeline:

```
User Question â†’ HyDE Expansion â†’ Enhanced Query
```

This bridges modern phrasing with scriptural language.

---

## âœ… 2. Vector Search with Similarity Filtering

Uses:

- `sentence-transformers/all-MiniLM-L6-v2`
- Normalized embeddings
- Cosine similarity
- Configurable similarity threshold

Weak matches are filtered out before response generation, reducing hallucination risk.

---

## âœ… 3. Context-Constrained Answering

The LLM is explicitly instructed to:

- Answer ONLY using retrieved context
- Refuse when information is insufficient
- Avoid external knowledge
- Limit responses to 5â€“6 lines

This enforces grounded generation.

---

## âœ… 4. Deterministic Embedding Architecture

- SHA256-based IDs prevent duplicate embeddings
- Automatic Chroma persistence
- Batch-based ingestion
- Stable vector IDs for reproducibility

---

# ğŸ— Architecture Overview

```
User Question
     â†“
HyDE Expansion (LLM)
     â†“
Enhanced Query = Question + HyDE
     â†“
Vector Search (ChromaDB)
     â†“
Similarity Threshold Filtering
     â†“
Context-Constrained LLM Response
     â†“
Answer + Sources Returned
```

---

# ğŸ“‚ Project Structure

```
rag-project-dev/
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ingest/
|   â”œâ”€â”€ download_dataset.py
â”‚   â”œâ”€â”€ clean_dataset.py
â”‚   â”œâ”€â”€ chunk_dataset.py
â”‚   â””â”€â”€ embed_chunks.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw.json
â”‚   â”œâ”€â”€ cleaned.json
â”‚   â””â”€â”€ chunk_dataset.json
â”‚
â”œâ”€â”€ chroma_db/
â””â”€â”€ README.md
```

---

# ğŸ“¦ Chunk Format

Structured Q&A storage format:

```json
{
  "text": "Answer text only",
  "metadata": {
    "source_question": "...",
    "source_file": "...",
    "type": "qa_explanation"
  }
}
```

Design goals:

- Question-aware retrieval
- Explanation-focused learning
- Clean metadata tracking
- Scalable toward verse-level upgrades

---

# âš™ï¸ Installation

## 1ï¸âƒ£ Create Virtual Environment

macOS / Linux:

```bash
python -m venv venv
source venv/bin/activate
```

Windows:

```powershell
python -m venv venv
venv\Scripts\Activate.ps1
```

---

## 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

Core dependencies include:

- fastapi
- uvicorn
- langchain
- langchain-chroma
- langchain-groq
- langchain-huggingface
- chromadb
- sentence-transformers
- python-dotenv

---

## 3ï¸âƒ£ Add Environment Variables

Create a `.env` file:

```
GROQ_API_KEY=your_api_key_here
```

---

# ğŸ“Š Data Ingestion Pipeline

## Step 1 â€” Download Dataset

```bash
python ingest/download_dataset.py
```

## Step 2 â€” Clean Dataset

```bash
python ingest/clean_dataset.py
```

Transforms raw Q&A into structured format.

---

## Step 3 â€” Chunk Dataset

```bash
python ingest/chunk_dataset.py
```

Features:

- Avoids over-splitting short answers
- Adds document metadata
- SHA256-based deduplication

---

## Step 4 â€” Embed into Chroma

```bash
python ingest/embed_chunks.py
```

Features:

- Normalized vectors
- Deterministic vector IDs
- Batch insertion
- Persistent storage

---

# ğŸ–¥ Running the API

From project root:

```bash
uvicorn api.main:app --reload
```

If inside `api/` directory:

```bash
uvicorn main:app --reload
```

Interactive API docs:

```
http://127.0.0.1:8000/docs
```
API runs at

```
http://127.0.0.1:8000
```

Start Web UI

```bash
streamlit run app.py
```
UI opens at

```
http://localhost:8501

```
---

# ğŸ“¡ API Usage

### POST `/ask`

### Request

```json
{
  "question": "What is the meaning of karma yoga?"
}
```

### Response

```json
{
  "answer": "...",
  "hyde_expansion": "...",
  "sources": [
    "Original source question text"
  ]
}
```

---

# ğŸ”’ Hallucination Minimization Strategy

| Technique | Implemented |
|------------|-------------|
| Temperature = 0 | âœ… |
| HyDE expansion | âœ… |
| Similarity threshold filtering | âœ… |
| Context-only answering | âœ… |
| Refusal behavior | âœ… |
| Deterministic embeddings | âœ… |

---

# ğŸ§  Current System Type

This project currently operates as:

> **Retrieval-Augmented FAQ Assistant for Bhagavad Gita Teachings**

It does **not yet** use verse-level scripture ingestion.

---

# ğŸš€ Planned Upgrade Path

- Ingest full Sanskrit + English translation
- Add chapter/verse metadata
- Enable precise scripture citation
- Hybrid BM25 + Vector retrieval
- Cross-encoder reranking
- Retrieval confidence scoring
- Self-verification LLM pass
- Async FastAPI optimization
- Docker deployment support

---

# ğŸ“ˆ System Maturity

This implementation includes:

- Multi-step retrieval reasoning
- HyDE-based semantic expansion
- Deterministic embedding architecture
- Structured ingestion pipeline
- Guarded LLM prompting
- GPU-accelerated embeddings

For an MVP devotional AI assistant, this is a robust and scalable foundation.

---

# ğŸ‘¨â€ğŸ’» Author

**Hrithik Umbarji**

Built with discipline, devotion, and a passion for spiritual learning.

---

# ğŸ•‰ï¸ Guiding Principle

â€œna hi jÃ±Änena sadá¹›Å›aá¹ pavitram iha vidyate.â€  
*There is nothing as purifying as true knowledge.* â€” Bhagavad Gita 4.38

---

â­ If this project supports your journey of learning and reflection, consider starring the repository.
